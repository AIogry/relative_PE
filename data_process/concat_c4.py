import os
from datasets import load_dataset, load_from_disk, concatenate_datasets
from itertools import islice
from tqdm import tqdm
import glob

OUTPUT_PATH = "/data/qijunrong/03-proj/PE/c4_30M_raw"
TARGET_SIZE = 30_000_000
BATCH_SIZE = 500_000

os.environ["HF_HOME"] = "/data/qijunrong/03-proj/PE/hf_cache"

print(f"ğŸ”§ ä¿®å¤åˆå¹¶é—®é¢˜...")

# æ£€æŸ¥å·²å®Œæˆçš„æ‰¹æ¬¡
existing_batches = glob.glob(os.path.join(OUTPUT_PATH, "batch_*"))
print(f"ğŸ“Š å‘ç°æ‰¹æ¬¡ç›®å½•: {len(existing_batches)} ä¸ª")

# æ­£ç¡®çš„åˆå¹¶æ–¹æ³•
final_datasets = []
success_count = 0

for i in range(60):  # æ£€æŸ¥æ‰€æœ‰60ä¸ªæ‰¹æ¬¡
    batch_path = os.path.join(OUTPUT_PATH, f"batch_{i:03d}")
    
    if os.path.exists(batch_path):
        try:
            # âœ… ä½¿ç”¨æ­£ç¡®çš„åŠ è½½æ–¹æ³•
            batch_ds = load_from_disk(batch_path)
            final_datasets.append(batch_ds)
            success_count += 1
            print(f"âœ… æˆåŠŸåŠ è½½æ‰¹æ¬¡ {i:03d}: {len(batch_ds):,} æ¡")
        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½æ‰¹æ¬¡ {i:03d}: {e}")
    else:
        print(f"âŒ æ‰¹æ¬¡ç›®å½•ä¸å­˜åœ¨: batch_{i:03d}")

if final_datasets:
    print(f"ğŸ”— åˆå¹¶ {len(final_datasets)} ä¸ªæ‰¹æ¬¡...")
    final_ds = concatenate_datasets(final_datasets)
    final_ds.save_to_disk(OUTPUT_PATH)
    print(f"ğŸ‰ åˆå¹¶å®Œæˆï¼æ€»æ ·æœ¬æ•°: {len(final_ds):,}")
else:
    print("âŒ æ²¡æœ‰å¯åˆå¹¶çš„æ•°æ®é›†")